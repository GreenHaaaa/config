# 顺丰科技实习日志

*2019年4月10日 刘林杰*

## 今天内容

- V1.7智慧中转平台需求开发代码自测和梳理

- 梳理quartz框架的使用
- 整理整体项目流程
  1. 定时通过kafka、api接口等方式获取外部系统的数据（DDS，OMCS等），先存入原始数据到mysql
  2. 获取任务后对数据按照一定的规则进行清洗后重新入库（mysql）
  3. 对数据进行展示（Web交互）
  4. 为模型服务提供数据进行分析
  5. ......(未完待续)
- 项目内quartz与kafka的应用场景
  - kafka的配置在disconf上面，使用@DisconfFile（filename=“”，name=“”）注解将配置读取。
  - 目前每天2点53分30秒( 30 53 02)的时候会将将所有kafka的消费者unRegister掉（），在这之前会定时（Spring scheduling + Quartz）执行清理任务（DDS，OMCS,单元区域，网点区域）的数据，并且注册kafka消息监听消息（外部数据）并且入库。此后开始散货和集货的数据的数据清洗。
- dubbo的@reference 探究
  - 昨天碰到相关的问题，今天debug进入referenceConfig看了下源码，目前得出的结论是在生成代理类（ReferenceConfig的createProxy（）方法）的时候，类内属性url在未在注解@Reference中配置url属性的类都是为空（即使在配置文件中dubbo：reference内配置了url），导致在生成代理类的时候没有按照dubbo直连的方式去生成代理类。目前对问题的进一步定位是，问题出在url的属性注入，具体暂时未知。

## 明天计划

- 梳理数据清洗的代码流程，以及理解相关业务名称
- 看到架构图中有数据分析的模块，明天找找看

## 体会感悟

- 根据项目内的代码以及外部的一些资料整理了一下quartz框架的一些基本知识和使用方式
  - 基本名称概念（有点多就不列出来了）
  - 基本使用
    - 定义一个Job接口的实现类，实现execute(JobExecutionContext context)方法
    - 为定义好的job实现类设置name group 以及在JobDataMap里面设置参数等信息，生成一个jobDetail类
    - 根据使用需求生成一个Schedule，内包含调度规则等
    - 将上述JobDetail以及schedule构建一个trigger
    - 将trigger注册到scheduler中
  - Schedule job调度执行规则
    - cron 调度的规则表达式（几天一次，几小时一次等，有特定的语法）
    - misfire 错失触发策略 因为某种原因在该触发的时候没有触发
  - trigger 触发器
    - startTIme和endTime 指定一个区间，区间外的时间不触发时间
    - 由jobDetail和schedule组合，注册在Scheduler中
  - scheduler 调度执行器

## 需要帮助

- 目前由于数据清洗的部分业务不太熟悉，代码阅读较为缓慢



